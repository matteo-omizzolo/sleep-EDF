# Default configuration for HDP-HMM sleep staging experiments

# Data settings
data:
  dataset: "sleep-edf-expanded"
  n_subjects: 30  # Number of subjects to use
  nights_per_subject: 1  # Use 1 night per subject
  channels: ["EEG Fpz-Cz"]  # Primary channel
  epoch_length: 30  # seconds
  sampling_rate: 100  # Hz

# Feature extraction
features:
  psd:
    method: "welch"
    nperseg: 256
    noverlap: 128
  bands:
    delta: [0.5, 4.0]
    theta: [4.0, 8.0]
    alpha: [8.0, 12.0]
    sigma: [12.0, 16.0]
    beta: [16.0, 30.0]
  log_transform: true
  standardize: true  # z-score per subject
  include_eog: true
  include_emg: true

# Model: HDP-HMM with sticky self-transitions
model:
  type: "hdp_hmm_sticky"  # Options: "idp_hmm", "hdp_hmm_sticky", "pooled_ihmm"
  
  # Hyperparameters
  concentration:
    gamma:
      # Global DP concentration (controls number of global states)
      distribution: "gamma"
      shape: 1.0
      rate: 1.0
      fixed: false  # Sample during inference
    
    alpha:
      # Group-level DP concentration (controls mixing over global states)
      distribution: "gamma"
      shape: 1.0
      rate: 1.0
      fixed: false
    
    kappa:
      # Sticky self-transition bias (encourages state persistence)
      distribution: "gamma"
      shape: 5.0
      rate: 1.0
      fixed: false
  
  # Emission distribution
  emissions:
    type: "gaussian"  # Multivariate Gaussian
    prior: "niw"  # Normal-Inverse-Wishart
    
    # NIW prior parameters (will be set based on data dimensionality)
    mu_0: null  # Prior mean (zero vector of feature dimension)
    kappa_0: 0.01  # Prior precision scaling
    psi: null  # Prior scale matrix (identity scaled by feature variance)
    nu: null  # Prior degrees of freedom (feature_dim + 2)

# Inference settings
inference:
  method: "weak_limit"  # Options: "weak_limit", "beam_sampler"
  
  # Truncation (for weak_limit)
  K_max: 50  # Maximum number of states
  
  # MCMC settings
  n_iter: 5000  # Total iterations
  burn_in: 2000  # Burn-in period
  thin: 5  # Thinning interval (save every 5th sample)
  n_chains: 3  # Number of parallel chains (for diagnostics)
  
  # Convergence diagnostics
  check_convergence: true
  r_hat_threshold: 1.1
  min_ess: 100
  
  # Initialization
  init_method: "kmeans"  # Options: "kmeans", "random", "prior"
  init_k: 10  # Initial number of states for k-means

# Evaluation settings
evaluation:
  # Cross-validation
  cv_method: "loso"  # Leave-one-subject-out
  n_folds: null  # null = use all subjects
  
  # Metrics
  metrics:
    - "log_likelihood"  # Predictive log-likelihood
    - "ari"  # Adjusted Rand Index
    - "nmi"  # Normalized Mutual Information
    - "macro_f1"  # Macro-averaged F1 score
  
  # Hungarian alignment
  hungarian:
    use_train_alignment: true  # Align on training set, apply to test
    min_cluster_size: 10  # Minimum epochs per state for alignment
  
  # Bootstrap uncertainty
  bootstrap:
    enabled: true
    n_samples: 1000
    ci_level: 0.95

# Logging and output
output:
  base_dir: "results"
  save_posterior_samples: true
  save_figures: true
  save_tables: true
  figure_format: "pdf"  # Options: "pdf", "png", "svg"
  
  # Plots to generate
  plots:
    - "posterior_num_states"
    - "state_sharing_heatmap"
    - "dwell_times"
    - "test_loglik"
    - "ari_nmi"
    - "states_vs_subjects"
    - "stick_breaking_weights"
    - "hypnogram_examples"
    - "ablation_kappa"
    - "trace_plots"
    - "transition_matrices"

# Reproducibility
random_seed: 42
deterministic: true

# Computational settings
compute:
  n_jobs: -1  # Number of parallel jobs (-1 = all CPUs)
  verbose: 1  # Verbosity level (0=silent, 1=progress, 2=debug)
  cache_features: true  # Cache preprocessed features
